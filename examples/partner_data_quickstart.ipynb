{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cf2e052-9c92-44bd-83f9-68ca40b3499b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Get Started with Data for Good Datasets\n",
    "\n",
    "This guide assumes you have already followed the steps [here](https://github.com/databricks-solutions/dais-2025-genai-hackathon?tab=readme-ov-file#1-set-up-your-workspace-and-get-data) to set up your workspace and send your Delta Sharing ID to request the partner data. It might take some time for the data to show up in the Delta Sharing section of your workspace. Once it is there, [add it as a catalog so you can use it in your workspace](https://github.com/databricks-solutions/dais-2025-genai-hackathon?tab=readme-ov-file#accessing-the-data).\n",
    "\n",
    "You will have access to three schemas:\n",
    "- `bright_initiative`\n",
    "- `mimilabs`\n",
    "- `nimble`\n",
    "\n",
    "with the data provided by each of these organizations.\n",
    "\n",
    "## How to Use This Guide\n",
    "The goal of this guide is to help you with the first steps of accessing these data and using them with AI tools. Your actual projects will most likely not look like these examples, but we hope showing how to start working with the data will help you get started!\n",
    "\n",
    "## Recommended Approach\n",
    "1. Follow the instruction [here](https://github.com/databricks-solutions/dais-2025-genai-hackathon?tab=readme-ov-file#1-set-up-your-workspace-and-get-data) to set up your workspace and get the data.\n",
    "2. Pick a theme or challenge you are interested in.\n",
    "3. Spend some time [exploring the data](#exploring-the-data) with AI/BI Genie spaces.\n",
    "4. Determine what your application needs to do with the data in order to solve the challenge you have chosen to pursue.\n",
    "5. Pick the framework or tools that are the best fit for your application.\n",
    "6. Build!\n",
    "\n",
    "## Exploring the Data\n",
    "\n",
    "To start exploring the data, we recommend creating one or more [AI/BI Genie Spaces](https://docs.databricks.com/aws/en/genie). Genie spaces let you ask natural language questions about the data you're interested in and get SQL queries, answers, and visualizations in return. It is a great way to quickly get up to speed on new data. You can access AI/BI Genie in the left sidebar in the `SQL` section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8df0bbbd-4993-4819-9b4f-c25e3b710d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Quickstart Code Snippets\n",
    "\n",
    "Here are some short code snippets showing how to start using the data once you've added the catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b30b8581-b220-455c-999f-d6639d55cfbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5867220f-0e13-42e1-b6b4-5959c67ffb2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqq langchain_core langchain_databricks langchain_community\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa4f2f59-8630-40ae-bd11-9862d5ebfc28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Bright Initiative\n",
    "\n",
    "The Bright Initiative has provided the following data:\n",
    "- **U.S. Google Maps Businesses Dataset - 5M Records:** Access detailed information on businesses across diverse industries in the U.S., including names, addresses, contact details, and ratings. \n",
    "- **Global Booking.com Hotel Listings Dataset: 1.6M Records:** The Booking dataset provides detailed and structured information on global accommodations, including hotel descriptions, location details, pricing, amenities, and guest reviews. It offers critical insights into property features, pricing trends, and customer preferences.\n",
    "- **Global Airbnb Properties Information Dataset: 1.6M Records:** Uncover the details of global Airbnb properties with this comprehensive dataset, providing vital information for travelers, property managers, and researchers. Access key property features such as price, images, descriptions, availability, reviews, and host details.\n",
    "\n",
    "Let's look at the Airbnb Properties Dataset. First, we'll start with a simple SQL query. You can query the datasets directly from a notebook or in the SQL Editor. Note that there are two different versions of the Bright Initiave datasets, differing mostly in whether nested columns are formatted as strings or arrays. Feel free to use whichever is more convenient for your use case.\n",
    "\n",
    "Here's how we might check the reviews of different Airbnb locations for mentions of wheelchair accessibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f548a381-786b-41ed-8c98-0851a6c364dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM `dais-hackathon-2025`.bright_initiative.airbnb_properties_information\n",
    "WHERE\n",
    "  location = 'Chicago, Illinois, United States'\n",
    "  AND host_number_of_reviews > 1000\n",
    "  AND EXISTS(reviews, review -> review ILIKE '%wheelchair%')\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8755b0a6-aafa-4038-9e38-3589cfa576a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Integrate with Agents\n",
    "\n",
    "Here is a naive approach to using these data with agents. We look for listings with reviews mentioning wheelchairs, extract a few fields with information about the listings (including reviews), and ask the model to describe the accessibility features of the listings.\n",
    "\n",
    "To expand on this approach and make it more suitable for your project, consider:\n",
    "- Letting the agent write the SQL for you, which allows it to answer flexible questions like \"are there any listings with a pool?\" without you needing to write a new query for every possible feature.\n",
    "- Combining keyword search with structured data for more powerful retrieval, so you can find reviews that mention \"spacious\" but only for listings with a guest rating above 4.8.\n",
    "- Giving your agent multiple \"tools\" to choose from, such as one function to query the Airbnb data and another to fetch live hotel prices from a different partner's API.\n",
    "- Integrate with other Bright data sources for a more holistic view of neighborhood accessibility, or for comparisons with other lodging options such as hotels.\n",
    "\n",
    "There are many tools, both from LangChain and Databricks, that can help with these steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06a27fc5-baff-441f-a0df-5300ef022b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "\n",
    "# configure workspace tokens\n",
    "w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\")\n",
    "\n",
    "def format_context(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Converts the DataFrame into a JSON string to ensure all data is passed\n",
    "    to the model without truncation. JSON is also a great format for structured data\n",
    "    like you have in 'description_by_sections'.\n",
    "    \"\"\"\n",
    "    return df.to_json(orient='records', indent=2)\n",
    "\n",
    "def find_accessible_airbnb_properties(location: str) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Queries the Bright Initiative Airbnb dataset for properties in a specific location\n",
    "  that have reviews mentioning \"wheelchair\".\n",
    "  \"\"\"\n",
    "  query = f\"\"\"\n",
    "    SELECT\n",
    "      listing_name,\n",
    "      location_details,\n",
    "      location,\n",
    "      details,\n",
    "      description_by_sections,\n",
    "      reviews\n",
    "    FROM `dais-hackathon-2025`.bright_initiative.airbnb_properties_information\n",
    "    WHERE\n",
    "      location ILIKE '%{location}%'\n",
    "      AND host_number_of_reviews > 1000\n",
    "      AND EXISTS(reviews, review -> review ILIKE '%wheelchair%')\n",
    "    LIMIT 5\n",
    "  \"\"\"\n",
    "  return format_context(spark.sql(query).toPandas())\n",
    "\n",
    "# Define the prompt template for the LLM\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "  \"\"\"\n",
    "  You are a helpful assistant for accessible travel. Your goal is to summarize potential Airbnb listings for a user.\n",
    "\n",
    "  The following listing *mention* wheelchairs but may not actually be accessible. Closely review the descriptions and review,\n",
    "  and then summarize the accessibility features (or lack thereof).\n",
    "\n",
    "  Here is the JSON data:\n",
    "  {context}\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\")\n",
    "\n",
    "# This is our simple \"agentic\" chain\n",
    "chain = (\n",
    "    find_accessible_airbnb_properties\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Let's run the chain for Chicago!\n",
    "result = chain.invoke(\"Chicago\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c4c1274-cae6-4e98-8f10-4d4c4a88cac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### mimilabs\n",
    "\n",
    "First, watch [this video](https://www.youtube.com/watch?v=2MYZ5WnrqDk) for help getting started. You can also use [mimibot](https://www.mimilabs.ai/mimibot) to ask questions about the provided data. The Delta Share with the data also includes two sample notebooks showing how to use these dataâ€”well worth consulting!\n",
    "\n",
    "These data are suitable for, among other things, building a \"benefits navigation agent\". Choosing a Medicare Advantage plan can be difficult and overwhelming, and there are a lot of opportunities for AI agents to help.\n",
    "\n",
    "First, let's set up the data as demonstrated in the example notebook provided via the Delta share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e75f9f2-a431-4982-8581-337abe213019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This query processes the raw PBP data and creates a clean, analysis-ready temporary view.\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW medicare_benefits_analysis AS\n",
    "WITH benefit_codes AS (\n",
    "  SELECT array(\n",
    "    '14c10', '14c11', '14c12', '14c13', '14c14', '14c15', '14c16', '14c17', '14c18', '14c19',\n",
    "    '14c20', '14c21', '14c22', '14c8', '14c9', '17a1', '17a2', '17b1', '17b2', '17b3',\n",
    "    '17b4', '17b5', '18a1', '18a2', '18b1', '18b2', '18b3', '18b4', '18c',\n",
    "    '13a', '7b1', '7b2', '16b1', '16b2', '16b3', '16b4', '16b5', '16b6',\n",
    "    '11a1', '11a2', '14c4', '6-1', '6-2', '6-3', '6-4', '13b',\n",
    "    '13i1', '13i2', '13i3', '13i4', '13i5', '13i6', '13i7', '13i8', '13i9', '13i10',\n",
    "    '13i11', '13i12', '13i13', '13i14', '13i15', '10b1', '10b2'\n",
    "  ) AS codes\n",
    "),\n",
    "latest_bids AS (\n",
    "  SELECT *\n",
    "  FROM (\n",
    "    SELECT *,\n",
    "           ROW_NUMBER() OVER (PARTITION BY bid_id ORDER BY version DESC) as rn\n",
    "    FROM `dais-hackathon-2025`.mimilabs.pbp_section_d\n",
    "    WHERE YEAR(mimi_src_file_date) = 2025\n",
    "  )\n",
    "  WHERE rn = 1\n",
    "),\n",
    "processed_bids AS (\n",
    "  SELECT\n",
    "    lb.*,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_1, ''), '\\\\s+', ''), ';'), x -> x != '') AS clean_cats_1,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_2, ''), '\\\\s+', ''), ';'), x -> x != '') AS clean_cats_2,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_3, ''), '\\\\s+', ''), ';'), x -> x != '') AS clean_cats_3,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_4, ''), '\\\\s+', ''), ';'), x -> x != '') AS clean_cats_4,\n",
    "    filter(split(regexp_replace(COALESCE(lb.pbp_d_combo_nmc_cats_5, ''), '\\\\s+', ''), ';'), x -> x != '') AS clean_cats_5\n",
    "  FROM latest_bids lb\n",
    "  CROSS JOIN benefit_codes bc\n",
    "  WHERE arrays_overlap(bc.codes,\n",
    "    filter(split(regexp_replace(CONCAT_WS(';',\n",
    "          COALESCE(lb.pbp_d_combo_nmc_cats_1, ''), COALESCE(lb.pbp_d_combo_nmc_cats_2, ''),\n",
    "          COALESCE(lb.pbp_d_combo_nmc_cats_3, ''), COALESCE(lb.pbp_d_combo_nmc_cats_4, ''),\n",
    "          COALESCE(lb.pbp_d_combo_nmc_cats_5, '')), '\\\\s+', ''), ';'), x -> x != '')\n",
    "  )\n",
    "),\n",
    "final_benefits AS (\n",
    "  SELECT\n",
    "    pb.pbp_a_hnumber,\n",
    "    pb.pbp_a_plan_identifier,\n",
    "    array_distinct(flatten(array(pb.clean_cats_1, pb.clean_cats_2, pb.clean_cats_3, pb.clean_cats_4, pb.clean_cats_5))) AS all_benefits\n",
    "  FROM processed_bids pb\n",
    ")\n",
    "SELECT\n",
    "  pbp_a_hnumber,\n",
    "  pbp_a_plan_identifier,\n",
    "  all_benefits,\n",
    "  arrays_overlap(all_benefits, array('13a')) AS has_acupuncture,\n",
    "  arrays_overlap(all_benefits, array('7b1', '7b2')) AS has_chiropractic,\n",
    "  arrays_overlap(all_benefits, array('16b1', '16b2', '16b3', '16b4', '16b5', '16b6')) AS has_dental,\n",
    "  arrays_overlap(all_benefits, array('11a1', '11a2')) AS has_dme,\n",
    "  arrays_overlap(all_benefits, array('14c4')) AS has_fitness,\n",
    "  arrays_overlap(all_benefits, array('6-1', '6-2', '6-3', '6-4')) AS has_home_health,\n",
    "  arrays_overlap(all_benefits, array('13b', '13i1', '13i2', '13i3', '13i4', '13i5', '13i6', '13i7', '13i8', '13i9', '13i10', '13i11', '13i12', '13i13', '13i14', '13i15')) AS has_otc_ssbci,\n",
    "  arrays_overlap(all_benefits, array('10b1', '10b2')) AS has_transportation\n",
    "FROM final_benefits\n",
    "\"\"\")\n",
    "\n",
    "print(\"Temporary view 'medicare_benefits_analysis' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "259b139e-cba4-4e7a-8e5e-a7c01449a929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's find plans that offer fitness benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e14197b-e6e9-4cbb-83f7-d04e630fbeeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Find the first 10 plans that offer fitness benefits\n",
    "SELECT *\n",
    "FROM\n",
    "  medicare_benefits_analysis\n",
    "WHERE\n",
    "  has_fitness = true\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "376442b0-4d59-4a5a-8126-932e75f70687",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Integrate with Agents\n",
    "Here is a simple approach to using these data in the context of the agents hackathon. To expand on this approach:\n",
    "- Using [mimibot](https://www.mimilabs.ai/mimibot), explore how these data relate to other tables provided by mimilabs, enabling you to further enrich the data\n",
    "- Explore other tools you could use that would enable more flexible retrieval than a hardcoded sql query\n",
    "- Connect to a web search tool that can enrich these data with user-friendly expalantions of benefits and what they mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d934fe69-3738-4af7-b5d4-1eeeb3f25d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from langchain_community.tools import tool\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "import ast\n",
    "\n",
    "@tool\n",
    "def find_plans_with_benefits(required_benefits: str) -> str:\n",
    "  \"\"\"\n",
    "  Finds Medicare Advantage plans that include all of the specified supplemental benefits.\n",
    "  Use this tool when a user asks to find plans with a specific list of benefits.\n",
    "  The input must be a Python list of benefit names provided as a string, chosen from:\n",
    "  'acupuncture', 'chiropractic', 'dental', 'dme', 'fitness', 'home_health', 'otc_ssbci', 'transportation'.\n",
    "  For example: \"['dental', 'fitness']\"\n",
    "  \"\"\"\n",
    "  try:\n",
    "    # The LLM often returns a string representation of a list, e.g., \"['dental', 'fitness']\".\n",
    "    # ast.literal_eval safely evaluates this string into an actual Python list.\n",
    "    benefits_list = ast.literal_eval(required_benefits)\n",
    "    if not isinstance(benefits_list, list):\n",
    "        raise ValueError(\"Input could not be parsed into a list.\")\n",
    "  except (ValueError, SyntaxError) as e:\n",
    "    # If parsing fails, return an error message to the agent so it can retry.\n",
    "    return f\"Error: Invalid input format. Expected a string representation of a list. {e}\"\n",
    "\n",
    "  # Build a WHERE clause from the list of required benefits\n",
    "  where_conditions = [f\"has_{benefit.strip()} = true\" for benefit in benefits_list]\n",
    "  where_clause = \" AND \".join(where_conditions)\n",
    "\n",
    "  query = f\"\"\"\n",
    "    SELECT pbp_a_hnumber, pbp_a_plan_identifier, all_benefits\n",
    "    FROM medicare_benefits_analysis\n",
    "    WHERE {where_clause}\n",
    "    LIMIT 10\n",
    "  \"\"\"\n",
    "  print(f\"Executing query: {query}\") # For debugging\n",
    "  df = spark.sql(query).toPandas()\n",
    "  return df.to_json(orient='records', indent=2)\n",
    "\n",
    "# Configure workspace client for authentication\n",
    "w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "# The LLM is the \"brain\" of the agent\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=2048)\n",
    "\n",
    "# The Agent needs a list of tools it can use\n",
    "tools = [find_plans_with_benefits]\n",
    "\n",
    "# This prompt template tells the agent how to reason about using tools\n",
    "# This is a standard \"ReAct\" (Reasoning + Acting) prompt\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent by combining the LLM, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Let's ask our agent a question in natural language!\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Can you find me some plans that have dental, fitness, and transportation benefits?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Final Answer ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5d613f6-4ba2-4e8c-84ee-a0ffb44e5516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Nimble\n",
    "\n",
    "See [this page](https://nimbleway.notion.site/Hackathon-Resource-Center-209c8a32950080f785e6cecc1e502a8b) for details on getting started with Nimble's MCP server and advice for using Nimble in the hackathon, and [this notebook](https://github.com/databricks-solutions/dais-2025-genai-hackathon/blob/main/2025_agent_hackathon_resources/nimble-mcp.ipynb) for instructions on using Nimble's MCP server with Databricks model serving via LangGraph and/or LlamaIndex.\n",
    "\n",
    "The Nimble team has also provided access to structured data from a variety of sources, such as amazon, footlocker, walmart, and yelp.\n",
    "\n",
    "Here's an example of working with the Amazon product data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf36860-88e2-4e83-8244-615768ff1ba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from `dais-hackathon-2025`.nimble.dbx_amazon_serp_daily limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f304927-0d60-4927-bf68-e55800a45c83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Integrate with Agents\n",
    "\n",
    "Here is a simple way to set up an agent to come up with multiple search terms and query the amazon products table for products to solve a given problem. To extend this for your hackathon project, you could:\n",
    "- Follow the links to get more information on the specific Amazon products\n",
    "- Obtain additional data sources using the Nimble MCP server\n",
    "- Use a multimodal model to evaluate the product images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eab4d73-2d5f-44c7-ad00-8693e7a63efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.tools import tool\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "\n",
    "\n",
    "@tool\n",
    "def find_products_by_keyword(search_term: str) -> str:\n",
    "  \"\"\"\n",
    "  Searches the Nimble e-commerce dataset for products matching a keyword search_term.\n",
    "  Use this to find products based on a user's request.\n",
    "  The input must be a single string. For example: \"clip on reading light\"\n",
    "  \"\"\"\n",
    "  query = f\"\"\"\n",
    "    SELECT\n",
    "      productId,\n",
    "      product_name,\n",
    "      price,\n",
    "      rating,\n",
    "      review_count,\n",
    "      product_url\n",
    "    FROM `dais-hackathon-2025`.nimble.dbx_amazon_serp_daily\n",
    "    WHERE\n",
    "      product_name ILIKE '%{search_term}%'\n",
    "    LIMIT 5\n",
    "  \"\"\"\n",
    "  print(f\"Executing query: {query}\") # For debugging\n",
    "  df = spark.sql(query).toPandas()\n",
    "  return df.to_json(orient='records', indent=2)\n",
    "\n",
    "  w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "# The LLM is the \"brain\" of the agent\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=2048)\n",
    "\n",
    "# The Agent needs a list of tools it can use\n",
    "tools = [find_products_by_keyword]\n",
    "\n",
    "# This prompt template tells the agent how to reason and use tools\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Your process should be to first think of a few different, specific search terms based on the user's question.\n",
    "Then, use the `find_products_by_keyword` tool for each of those keywords, one at a time.\n",
    "After you have gathered all the product information from your searches, combine the results into a single, helpful summary for the user.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: After you find the products from all your searches, your final answer should summarize them and suggest that a good next step would be to use a web browsing tool to analyze the product pages for more detailed information.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent by combining the LLM, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Let's ask our agent to find a product related to accessibility\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"I'm looking for a tool to help my elderly parent open tight jars.\"\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Final Answer ---\")\n",
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8102901750420320,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "partner_data_quickstart",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
